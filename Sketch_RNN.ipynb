{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Sketch_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd2Bj8kwDoHg"
      },
      "source": [
        "# Sketch-RNN with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDKgXnI7OpgK"
      },
      "source": [
        "#I've provided multiple options to load the folder into the Colab notebook\n",
        "#choose any one and comment the rest \n",
        "\n",
        "#zip the folder, upload it and unzip it.\n",
        "\n",
        "#Load the folder from your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/sketch_gen\n",
        "\n",
        "\n",
        "#Load the folder from GitHub\n",
        "#!git clone https://github.com/Jagadish2000/Sketch_gen.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bxw0QoqEU5X"
      },
      "source": [
        "#before training the model, make sure the epochs,enc_rnn_size,dec_rnn_size (in seq2seq_VAE.py) are correct\n",
        "#to train multiple datasets, goto seq2seq_VAE.py and -> 'data_set': ['first_dataset','second_dataset']\n",
        "\n",
        "\n",
        "!python3 seq2seqVAE_train.py \\--data_dir=datasets \\--experiment_dir=experiments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS9ngWFvDoHs"
      },
      "source": [
        "In this notebook we will play around with the models we trained using the [Keras Sketch-RNN](https://github.com/eyalzk/sketch_rnn_keras).\n",
        "We will load the trained models, draw some sketches, travel along the latent space and explore what our model has learned.\n",
        "\n",
        "many examples in this notebook are ported to keras from the [official Magenta demo](https://github.com/tensorflow/magenta-demos/blob/master/jupyter-notebooks/Sketch_RNN.ipynb) and some are my own."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uatRohvpDoHt"
      },
      "source": [
        "First, let's set our experiment directory and the checkpoint file that we want to load.\n",
        "\n",
        "We'll start with a model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL35VyQ-DoHu"
      },
      "source": [
        "# Path to data directory \n",
        "data_dir  = '/content/drive/MyDrive/sketch_gen/datasets'\n",
        "# Path to the experiment directory that was created during training\n",
        "exp_dir = '/content/drive/MyDrive/sketch_gen/experiments/cat/exp_0'\n",
        "# Checkpoint file name (assumed in checkpoints folder within exp_dir)\n",
        "weights_fname = 'weights.01-0.59.hdf5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOiXT-Z2DoHv"
      },
      "source": [
        "Now let's do some imports and define functions that we will use later on:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T1uv1IuDoHw"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/sketch_rnn_keras-master')\n",
        "import os\n",
        "import copy\n",
        "from utils import *\n",
        "from seq2seqVAE_train import *\n",
        "import seq2seqVAE as sketch_rnn_model\n",
        "from seq2seqVAE import sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE3QrxfWDoHx"
      },
      "source": [
        "!pip install svgwrite\n",
        "# libraries required for visualisation:\n",
        "from IPython.display import SVG, display\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import svgwrite \n",
        "# set numpy output to something sensible\n",
        "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syXHmLaEDoHy"
      },
      "source": [
        "The following few functions are mostly the same as in the official Magenta demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SihC3T-hDoHz"
      },
      "source": [
        "# little function that displays vector images and saves them to .svg\n",
        "def draw_strokes(data, factor=0.2, svg_filename = '/tmp/sketch_rnn/svg/sample.svg'):\n",
        "    if not os.path.exists(os.path.dirname(svg_filename)):\n",
        "        os.makedirs(os.path.dirname(svg_filename))\n",
        "    min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
        "    dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
        "    dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
        "    dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
        "    lift_pen = 1\n",
        "    abs_x = 25 - min_x \n",
        "    abs_y = 25 - min_y\n",
        "    p = \"M%s,%s \" % (abs_x, abs_y)\n",
        "    command = \"m\"\n",
        "    for i in range(len(data)):\n",
        "        if (lift_pen == 1):\n",
        "            command = \"m\"\n",
        "        elif (command != \"l\"):\n",
        "            command = \"l\"\n",
        "        else:\n",
        "            command = \"\"\n",
        "        x = float(data[i,0])/factor\n",
        "        y = float(data[i,1])/factor\n",
        "        lift_pen = data[i, 2]\n",
        "        p += command+str(x)+\",\"+str(y)+\" \"\n",
        "    the_color = \"black\"\n",
        "    stroke_width = 1\n",
        "    dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
        "    dwg.save()\n",
        "    display(SVG(dwg.tostring()))\n",
        "\n",
        "# generate a 2D grid of many vector drawings\n",
        "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=16.0):\n",
        "    def get_start_and_end(x):\n",
        "        x = np.array(x)\n",
        "        x = x[:, 0:2]\n",
        "        x_start = x[0]\n",
        "        x_end = x.sum(axis=0)\n",
        "        x = x.cumsum(axis=0)\n",
        "        x_max = x.max(axis=0)\n",
        "        x_min = x.min(axis=0)\n",
        "        center_loc = (x_max+x_min)*0.5\n",
        "        return x_start-center_loc, x_end\n",
        "    x_pos = 0.0\n",
        "    y_pos = 0.0\n",
        "    result = [[x_pos, y_pos, 1]]\n",
        "    for sample in s_list:\n",
        "        s = sample[0]\n",
        "        grid_loc = sample[1]\n",
        "        grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
        "        grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
        "        start_loc, delta_pos = get_start_and_end(s)\n",
        "    \n",
        "        loc_x = start_loc[0]\n",
        "        loc_y = start_loc[1]\n",
        "        new_x_pos = grid_x+loc_x\n",
        "        new_y_pos = grid_y+loc_y\n",
        "        result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
        "    \n",
        "        result += s.tolist()\n",
        "        result[-1][2] = 1\n",
        "        x_pos = new_x_pos+delta_pos[0]\n",
        "        y_pos = new_y_pos+delta_pos[1]\n",
        "    return np.array(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApWA5dbHDoH1"
      },
      "source": [
        "Read parameter file and load data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1qoQ5BeDoH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefa9096-98b7-4797-d1cc-ba193c9577fc"
      },
      "source": [
        "with open(os.path.join(exp_dir,'logs', 'model_config.json'), 'r') as f:\n",
        "    model_params = json.load(f)\n",
        "model_params = DotDict(model_params)   \n",
        "[train_set, valid_set, test_set, hps_model] = load_dataset(data_dir, model_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 70000/2500/2500 from cat.npz\n",
            "Dataset combined: 75000 (70000/2500/2500), avg len 69\n",
            "model_params.max_seq_len: 129\n",
            "total images <= max_seq_len is 70000\n",
            "total images <= max_seq_len is 2500\n",
            "total images <= max_seq_len is 2500\n",
            "normalizing_scale_factor  43.17017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrrAK-RHDoH4"
      },
      "source": [
        "Build a Seq2seq variational autoencoder model and load weights from checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU1avfq8DoH4"
      },
      "source": [
        "weights = os.path.join(exp_dir,'checkpoints',weights_fname) # checkpoint path\n",
        "seq2seq = Seq2seqModel(model_params)  # build model\n",
        "seq2seq.load_trained_weights(weights) # load checkpoint\n",
        "seq2seq.make_sampling_models()  # build sub models that are used to infuse inputs and probe values of intermediate layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agCa0XRMDoH5"
      },
      "source": [
        "# Function for encoding input and retrieving latent vector\n",
        "def encode(input_strokes, draw=False):\n",
        "    strokes = to_big_strokes(input_strokes, max_len=model_params['max_seq_len']-1).tolist()\n",
        "    strokes.insert(0, [0, 0, 1, 0, 0])\n",
        "    seq_len = [len(input_strokes)]\n",
        "    if draw:\n",
        "        draw_strokes(to_normal_strokes(np.array(strokes)))\n",
        "    strokes = np.expand_dims(strokes, axis=0)\n",
        "    return seq2seq.sample_models['encoder_model'].predict(strokes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD89hno3DoH6"
      },
      "source": [
        "# Function for decoding a latent space factor into a sketch\n",
        "def decode(z_input=None, draw_mode=True, temperature=0.1, factor=0.2):\n",
        "    z = None\n",
        "    if z_input is not None:\n",
        "        z = z_input\n",
        "    sample_strokes, m = sample(seq2seq, seq_len=model_params.max_seq_len, temperature=temperature, z=z)\n",
        "    strokes = to_normal_strokes(sample_strokes)\n",
        "    if draw_mode:\n",
        "        draw_strokes(strokes, factor)\n",
        "    return strokes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM4hdFk2DoH7"
      },
      "source": [
        "Let's take a random sketch from the unseen test set and draw it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "V_bDCa2EDoH7"
      },
      "source": [
        "# Get a sample drawing from the test set, and render it to .svg\n",
        "stroke = test_set.random_sample()\n",
        "draw_strokes(stroke,svg_filename = '/tmp/sketch_rnn/svg/sample.svg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0P2iIVaDoH8"
      },
      "source": [
        "Now we will encode this sketch into the latent space.\n",
        "\n",
        "Note that our encoder was constructed to be non-deterministic. So the same sketch will be encoded to different latent representations each time we encode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKZ6v3dPDoH-"
      },
      "source": [
        "z = encode(stroke)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzzaQ2eDDoH-"
      },
      "source": [
        "Now we decode this encoded representation back to a sketch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVq-aWUaDoH_"
      },
      "source": [
        "_ = decode(z, temperature=0.5) # convert z back to drawing at temperature of 0.5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5rysK8sDoIA"
      },
      "source": [
        "The temperature variable controls the level of randomness we would like our samples to have during the\n",
        "sampling (equation 8 of the sketch-rnn [paper](https://arxiv.org/pdf/1704.03477.pdf)).\n",
        "\n",
        "Let's decode our cat using varying temperature values between 0.1 and 1 and see how 'creative' our model can get:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WTgs0dhrDoIA"
      },
      "source": [
        "stroke_list = []\n",
        "for i in range(10):\n",
        "  stroke_list.append([decode(z, draw_mode=False, temperature=0.1*i+0.1), [0, i]])\n",
        "stroke_grid = make_grid_svg(stroke_list)\n",
        "draw_strokes(stroke_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXYXn97rDoIB"
      },
      "source": [
        "OK, so we saw how to encode and decode a single sketch.\n",
        "Now let's see what happens when we interpolate between two different cats!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "OlwyTspJDoIB"
      },
      "source": [
        "z0 = z\n",
        "\n",
        "# Get a sample drawing from the test set, and render it to .svg\n",
        "stroke = test_set.random_sample()\n",
        "draw_strokes(stroke,svg_filename = '/tmp/sketch_rnn/svg/sample.svg')\n",
        "z1 = encode(stroke)\n",
        "_ = decode(z1) # convert z back to drawing at temperature of 0.5\n",
        "\n",
        "z1 = np.squeeze(z1)\n",
        "z0 = np.squeeze(z0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ViGcUmRDoIC"
      },
      "source": [
        "def interpolate_z(z_0, z_1, draw=True):\n",
        "    z_list = [] # interpolate spherically between z0 and z1\n",
        "    N = 10\n",
        "    for t in np.linspace(0, 1, N):\n",
        "        z_list.append(slerp(z_0, z_1, t))\n",
        "    # for every latent vector in z_list, sample a vector image\n",
        "    reconstructions = []\n",
        "    for i in range(N):\n",
        "        reconstructions.append([decode(np.expand_dims(z_list[i],axis=0), draw_mode=False), [0, i]])\n",
        "    stroke_grid = make_grid_svg(reconstructions)\n",
        "    if draw:\n",
        "        draw_strokes(stroke_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "gl2blUEFDoID"
      },
      "source": [
        "interpolate_z(z0,z1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPcIU4zEDoID"
      },
      "source": [
        "Since this is a Variational Autoencoder, we don't need to use an actual sketch in order to generate new sketches. We can sample randomly within the latent space and feed the result to the decoder.\n",
        "\n",
        "Let's let our model draw some random cats!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "wx0gAGXNDoIE"
      },
      "source": [
        "random_cat_1 = np.expand_dims(np.random.randn(model_params.z_size),0)\n",
        "_ = decode(random_cat_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5dTC7h0vDoIE"
      },
      "source": [
        "random_cat_2 = np.expand_dims(np.random.randn(model_params.z_size),0)\n",
        "_ = decode(random_cat_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69yy7CfqDoIF"
      },
      "source": [
        "Again, we can intepulate between our 2 random cats:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1pZ6zaHgDoIF"
      },
      "source": [
        "random_cat_1 = np.squeeze(random_cat_1)\n",
        "random_cat_2 = np.squeeze(random_cat_2)\n",
        "# interpolate_z(random_cat_2,random_cat_2)\n",
        "interpolate_z(random_cat_1,random_cat_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be7_dd22DoIG"
      },
      "source": [
        "### Using a model trained on more than one data-set\n",
        "Now let's load a model trained on both **cats** and **guitars**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlYIFW2PDoIH"
      },
      "source": [
        "# Path to the experiment directory that was created during training\n",
        "exp_dir = 'examples\\experiments\\cat_guitar'\n",
        "# Checkpoint file name (assumed in checkpoints folder within exp_dir)\n",
        "weights_fname = 'weights.hdf5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7_mX2CNDoIH"
      },
      "source": [
        "with open(os.path.join(exp_dir,'logs', 'model_config.json'), 'r') as f:\n",
        "    model_params = json.load(f)\n",
        "model_params = DotDict(model_params)   \n",
        "[train_set, valid_set, test_set, hps_model] = load_dataset(data_dir, model_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRse6fxTDoII"
      },
      "source": [
        "weights = os.path.join(exp_dir,'checkpoints',weights_fname) # checkpoint path\n",
        "seq2seq = Seq2seqModel(model_params)  # build model\n",
        "seq2seq.load_trained_weights(weights) # load checkpoint\n",
        "seq2seq.make_sampling_models()  # build sub models that are used to infuse inputs and probe values of intermediate layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75RxG4twDoIJ"
      },
      "source": [
        "Cat sketch reconstruction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQpHQr8bDoIJ"
      },
      "source": [
        "# Get a sample drawing from the test set, and render it to .svg\n",
        "stroke = test_set.random_sample()\n",
        "draw_strokes(stroke,svg_filename = '/tmp/sketch_rnn/svg/sample.svg')\n",
        "z_cat = encode(stroke)\n",
        "_ = decode(z_cat) # convert z back to drawing at temperature of 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqr-IYRtDoIK"
      },
      "source": [
        "Guitar sketch reconstruction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFv-Hpo_DoIK"
      },
      "source": [
        "# Get a sample drawing from the test set, and render it to .svg\n",
        "stroke = test_set.random_sample()\n",
        "draw_strokes(stroke,svg_filename = '/tmp/sketch_rnn/svg/sample.svg')\n",
        "z_guitar = encode(stroke)\n",
        "_ = decode(z_guitar) # convert z back to drawing at temperature of 0.5\n",
        "\n",
        "z_guitar = np.squeeze(z_guitar)\n",
        "z_cat = np.squeeze(z_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0bIt6ZZDoIL"
      },
      "source": [
        "Interpolating from cat to guitar!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LO_9ypvnDoIL"
      },
      "source": [
        "interpolate_z(z_cat,z_guitar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKgCsFDGDoIM"
      },
      "source": [
        "Examples in this notebook use models trained on my laptop's GPU:\n",
        "  * Cat model : 50 epochs\n",
        "  * Cat + Guitar model: 15 epochs\n",
        " \n",
        "Given more time and resources I expect results to be even better than ones shown here."
      ]
    }
  ]
}